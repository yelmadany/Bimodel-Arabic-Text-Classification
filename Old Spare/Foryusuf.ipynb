{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "import time\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.initializers import glorot_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image2(img):\n",
    "    # Apply median filter for noise removal\n",
    "    img_median = cv2.medianBlur(img, 3)\n",
    "\n",
    "    # Convert the image to grayscale for OTSU thresholding\n",
    "    img_gray = cv2.cvtColor(img_median, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply OTSU thresholding for binarization\n",
    "    _, binary_image = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Convert binary image to 3 channels\n",
    "    binary_image_3_channels = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Display the original, median-filtered, and binarized images for comparison\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(131), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.title('Original Image')\n",
    "    # plt.subplot(132), plt.imshow(cv2.cvtColor(img_median, cv2.COLOR_BGR2RGB)), plt.title('Median Filtered')\n",
    "    # plt.subplot(133), plt.imshow(binary_image_3_channels), plt.title('Binarized (3 channels)')\n",
    "    # plt.show()\n",
    "\n",
    "    return binary_image_3_channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.5 GiB for an array with shape (1922, 800, 800, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Yo200\\Downloads\\DL Project\\Foryusuf.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     all_labels\u001b[39m.\u001b[39mappend(labels_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Concatenate the batches to create the final arrays\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m all_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(all_images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m all_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(all_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Now, 'all_images' contains all the images and 'all_labels' contains their corresponding labels\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Yo200/Downloads/DL%20Project/Foryusuf.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 27.5 GiB for an array with shape (1922, 800, 800, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the updated Excel file\n",
    "updated_excel_file = 'updated_excel_file.xlsx'\n",
    "data = pd.read_excel(updated_excel_file, usecols=range(5))  # Load only the first 5 columns\n",
    "width = height = 800\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def load_images_and_labels(file_names_column, age_column, start_idx, end_idx):\n",
    "    images_batch = []\n",
    "    labels_batch = []\n",
    "    \n",
    "    for index in range(start_idx, end_idx):\n",
    "        row = data.iloc[index]\n",
    "        file_name = row[file_names_column]\n",
    "        age = row[age_column]\n",
    "\n",
    "        if pd.notnull(age) and pd.notnull(file_name):\n",
    "            image = cv2.imread(os.path.join('./images', file_name))\n",
    "            image = preprocess_image2(image)\n",
    "            image = cv2.resize(image, (width, height))\n",
    "            images_batch.append(image)\n",
    "            labels_batch.append(age)\n",
    "\n",
    "    labels_batch = to_categorical(labels_batch, num_classes=2)\n",
    "    images_batch = np.array(images_batch) / 255.0\n",
    "    \n",
    "    return images_batch, labels_batch\n",
    "\n",
    "# Load all images and labels\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for start_idx in range(0, len(data), batch_size):\n",
    "    end_idx = min(start_idx + batch_size, len(data))\n",
    "    images_batch, labels_batch = load_images_and_labels('File Name', 'Gender', start_idx, end_idx)\n",
    "    \n",
    "    all_images.append(images_batch)\n",
    "    all_labels.append(labels_batch)\n",
    "\n",
    "# Concatenate the batches to create the final arrays\n",
    "all_images = np.concatenate(all_images)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Now, 'all_images' contains all the images and 'all_labels' contains their corresponding labels\n",
    "\n",
    "# Example usage\n",
    "print(all_images.shape)  # Print the shape of the array containing all images\n",
    "print(all_labels.shape)  # Print the shape of the array containing all labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import ResNet50,MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create the actual and predicted\n",
    "# vectors for further evaluation.\n",
    "\n",
    "def generate_actual_predicted(model, X_test, Y_test):\n",
    "    # Get the predictions\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Create a list of predictions\n",
    "\n",
    "    #Converting predictions to label\n",
    "    predicted = list()\n",
    "    for i in range(len(Y_pred)):\n",
    "        predicted.append(np.argmax(Y_pred[i]))\n",
    "\n",
    "    #Converting one hot encoded test label back to label\n",
    "    actual = list()\n",
    "    for i in range(len(Y_test)):\n",
    "        actual.append(np.argmax(Y_test[i]))\n",
    "\n",
    "    return actual, predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# save the best model \n",
    "filepath='best_modelNew'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will only use the training data \n",
    "# and test it on each partition\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "n_split=5\n",
    "\n",
    "# We will split the the data n_split times\n",
    "# and create and for the model with the said\n",
    "# parameters\n",
    "images1=all_images[:1000]\n",
    "labels1=all_labels[:1000]\n",
    "results = list()\n",
    "for train_index,test_index in KFold(n_split).split(images1): \n",
    "  # use the index to generate training an testing sets\n",
    "  x_train,x_test=images1[train_index],images1[test_index]\n",
    "  y_train,y_test=labels1[train_index],labels1[test_index]\n",
    "  \n",
    "  # create and fit the model\n",
    "#   model=build_model1()\n",
    "          # Input tensor\n",
    "  #   width=height=1000\n",
    "  base_model = MobileNet(include_top=False, weights='imagenet', input_shape=(width, height, 3), pooling='avg',\n",
    "                          alpha=1.0, depth_multiplier=1, dropout=.2)\n",
    "  base_model.trainable = False\n",
    "  x_top = base_model.output\n",
    "  x_out = Dense(128, activation='relu')(x_top)\n",
    "  out=Dense(2, activation='softmax')(x_out)\n",
    "\n",
    "  model = Model(base_model.input, out)\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  #model1.summary()\n",
    "\n",
    "  # Train the model\n",
    "  history =model.fit(x_train, y_train,epochs=10, batch_size = 32,callbacks = callbacks_list, validation_split=0.2)\n",
    "\n",
    "\n",
    "\n",
    "  #history =bilinear_model.fit(x_train, y_train,epochs=20, batch_size = 32,callbacks = callbacks_list, validation_split=0.2)\n",
    "  \n",
    "  # print and show generic metrics available\n",
    "  scores = model.evaluate(x_test,y_test)\n",
    "\n",
    "  # print the model metrics\n",
    "  for i,names in zip(np.arange(0,len(model.metrics_names)),model.metrics_names):\n",
    "      print(model.metrics_names[i],'=',scores[i])\n",
    "  # calculate and print more metrics\n",
    "  actual, predicted = generate_actual_predicted(model, x_test, y_test)\n",
    "  print(\"precision \",precision_score(actual, predicted, average='macro'))\n",
    "  print(\"recall \", recall_score(actual, predicted, average='macro'))\n",
    "  print(\"F1-Score \", f1_score(actual, predicted, average='macro'))\n",
    "  results.append([precision_score(actual, predicted, average='macro'),\n",
    "                  recall_score(actual, predicted, average='macro'), \n",
    "                  f1_score(actual, predicted, average='macro') ])\n",
    "  \n",
    "  \n",
    "  #del bilinear_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
